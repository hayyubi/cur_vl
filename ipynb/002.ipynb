{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a set of nouns for open-vocabulary inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tokenization_bert import BasicTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.modeling.language_backbone.transformers import BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/coco/annotations/captions_train2017.json', 'r') as fin:\n",
    "    coco_train_anno_all = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BasicTokenizer(do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "for item in coco_train_anno_all['annotations']:\n",
    "    tokens = tokenizer.tokenize(item['caption'])\n",
    "    for word, pos in nltk.pos_tag(tokens):\n",
    "        if pos == 'NN':\n",
    "            nouns.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {item: 0 for item in set(nouns)}\n",
    "for item in nouns:\n",
    "    counts[item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_mtx = [[item, counts[item]] for item in counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_mtx = np.asarray(counts_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(- counts_mtx[:, 1].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['man', '73340'],\n",
       "       ['woman', '34210'],\n",
       "       ['street', '30182'],\n",
       "       ['table', '27975'],\n",
       "       ['person', '24745'],\n",
       "       ['group', '21599'],\n",
       "       ['top', '21228'],\n",
       "       ['field', '20779'],\n",
       "       ['tennis', '19409'],\n",
       "       ['front', '19057'],\n",
       "       ['train', '18431'],\n",
       "       ['plate', '18324'],\n",
       "       ['room', '18321'],\n",
       "       ['dog', '18064'],\n",
       "       ['cat', '17041'],\n",
       "       ['water', '16513'],\n",
       "       ['baseball', '15704'],\n",
       "       ['bathroom', '14433'],\n",
       "       ['sign', '13946'],\n",
       "       ['food', '13242']], dtype='<U18')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_mtx[sort_idx][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['celery', '100'],\n",
       "       ['pigeon', '100'],\n",
       "       ['maker', '100'],\n",
       "       ['individual', '99'],\n",
       "       ['mid', '99'],\n",
       "       ['asphalt', '98'],\n",
       "       ['coast', '98'],\n",
       "       ['drawing', '98'],\n",
       "       ['ad', '98'],\n",
       "       ['hipster', '98']], dtype='<U18')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_mtx[sort_idx][1160:1170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_to_emb = {}\n",
    "with open('../datasets/coco/zero-shot/glove.6B.300d.txt', 'r') as fin:\n",
    "    for row in fin:\n",
    "        row_tk = row.split()\n",
    "        if row_tk[0] in counts:\n",
    "            class_name_to_emb[row_tk[0]] = [float(num) for num in row_tk[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11678"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_name_to_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_filtered = []\n",
    "for item in counts_mtx[sort_idx]:\n",
    "    if item[0] in class_name_to_emb:\n",
    "        counts_filtered.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_filtered = counts_filtered[:1161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['wheelchair', '102'], dtype='<U18'),\n",
       " array(['gravy', '101'], dtype='<U18'),\n",
       " array(['cutter', '101'], dtype='<U18'),\n",
       " array(['loaf', '101'], dtype='<U18'),\n",
       " array(['pajamas', '100'], dtype='<U18'),\n",
       " array(['lying', '100'], dtype='<U18'),\n",
       " array(['porcelain', '100'], dtype='<U18'),\n",
       " array(['celery', '100'], dtype='<U18'),\n",
       " array(['pigeon', '100'], dtype='<U18'),\n",
       " array(['maker', '100'], dtype='<U18')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_filtered[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [class_name_to_emb[item[0]] for item in counts_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.asarray(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [item[0] for item in counts_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/coco/zero-shot/ov_nouns.pkl', 'wb') as fout:\n",
    "    pickle.dump((class_names, embeddings), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BERT(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = bert.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_class_list = bert(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (1 - encoded_class_list['special_tokens_mask']).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertembeddings = (encoded_class_list['input_embeddings'] * mask[:, :, None]).sum(1) / mask.sum(1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertembeddings = bertembeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertembeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/coco/zero-shot/ov_nouns_bertemb.pkl', 'wb') as fout:\n",
    "    pickle.dump((class_names, bertembeddings), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "maskrcnn2",
   "language": "python",
   "name": "maskrcnn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
