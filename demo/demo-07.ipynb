{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-Vocabulary Object Detection Demo\n",
    "\n",
    "This notebook creates a side-by-side GIF animation comparing our method in generalized zero-shot mode vs. a supervised baseline trained on seen classes.\n",
    "\n",
    "Let's start with a few standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "import imageio\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "from predictor import COCODemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.plugins.freeimage.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2 = deepcopy(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_list([\n",
    "    \"MODEL.WEIGHT\", \"/home/alireza/workspace/ovo/runs-new/maskrcnn/130-rep/model_0120000.pth\",\n",
    "    \"MODEL.CLS_AGNOSTIC_BBOX_REG\", True,\n",
    "    \"MODEL.ROI_BOX_HEAD.EMB_DIM\", 768,\n",
    "    \"MODEL.ROI_BOX_HEAD.EMBEDDING_BASED\", True,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `COCODemo` object. It contains a few extra options for conveniency, such as the confidence threshold for detections to be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_demo = COCODemo(\n",
    "    cfg,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading classes and their embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = '../datasets/coco/zero-shot/instances_val2017_all_2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ann_file, 'r') as fin:\n",
    "    ann_data = json.load(fin)\n",
    "class_embeddings = [np.zeros((768,), dtype=np.float32)]\n",
    "class_names = ['__background']\n",
    "for item in ann_data['categories']:\n",
    "    class_embeddings.append(np.asarray(\n",
    "        item['embedding']['BertEmb'], \n",
    "        dtype=np.float32))\n",
    "    class_names.append(item['name'])\n",
    "class_embeddings = np.stack(class_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file2 = '../datasets/coco/zero-shot/instances_val2017_seen.json'\n",
    "with open(ann_file2, 'r') as fin:\n",
    "    ann_data2 = json.load(fin)\n",
    "class_names2 = ['__background']\n",
    "for item in ann_data2['categories']:\n",
    "    class_names2.append(item['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_indices = [i for i, l in enumerate(class_names) if l not in class_names2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 12, 13, 16, 17, 22, 24, 28, 30, 33, 35, 46, 48, 55, 59, 64]\n"
     ]
    }
   ],
   "source": [
    "print(unseen_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_demo.CATEGORIES = class_names\n",
    "coco_demo.UNSEEN_CAT_INDICES = unseen_indices\n",
    "coco_demo.model.roi_heads['box'].predictor.set_class_embeddings(class_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the same to setup the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2.merge_from_list([\n",
    "    \"MODEL.WEIGHT\", \"/home/alireza/workspace/ovo/runs-extra-ckpt/maskrcnn/004/model_0180000.pth\",\n",
    "    \"MODEL.CLS_AGNOSTIC_BBOX_REG\", True,\n",
    "    \"MODEL.ROI_BOX_HEAD.NUM_CLASSES\", 81,\n",
    "    \"MODEL.ROI_BOX_HEAD.EMBEDDING_BASED\", False,\n",
    "])\n",
    "coco_demo_2 = COCODemo(\n",
    "    cfg2,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.7,\n",
    ")\n",
    "coco_demo_2.CATEGORIES = class_names2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading each frame of each video, processing it through two models, visualizing each, stitching side by side, and saving to a new video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../datasets/videos/input/02/'\n",
    "output_path = '../../outputs/rcnn_ov/videos/02.01/'\n",
    "file_list = os.listdir(input_path)\n",
    "assert not os.path.isdir(output_path)\n",
    "os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uUUWejExcLk.mp4',\n",
       " '9HF9a9P-lLw.mp4',\n",
       " '4vGaWRRs1cc.mp4',\n",
       " 'bhWhuUhAbqk.mp4',\n",
       " 'ufpqxRukWaI.mp4',\n",
       " 'mGVHNXcwcKk.mp4',\n",
       " 'JSvwWs7PIsw.mp4',\n",
       " 'LYBKNaGad7o.mp4',\n",
       " '0xBxtyxw488.mp4',\n",
       " 'cF0316u8OG4.mp4',\n",
       " 'vOO_fDMyRiM.mp4',\n",
       " 'Ehbg7RUmk.mp4',\n",
       " 'EiLpNm8C0TM.mp4',\n",
       " 'IxGPyoml9C4.mp4',\n",
       " 'mqFXobS9KTw.mp4']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    '9HF9a9P-lLw.mp4',\n",
    "    'cF0316u8OG4.mp4',\n",
    "    'IxGPyoml9C4.mp4',    \n",
    "    'vOO_fDMyRiM.mp4',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = False\n",
    "side_by_side = True\n",
    "generate_video = True\n",
    "generate_gif = False\n",
    "\n",
    "for fname in file_list:\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(os.path.join(input_path, fname))\n",
    "        out_sol = None\n",
    "        out_sbs = None\n",
    "        gif_sol = []\n",
    "        gif_sbs = []\n",
    "        opened = False\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                if not opened:\n",
    "                    raise Exception(\"Cannot open input file.\")\n",
    "                break\n",
    "            opened = True\n",
    "            if generate_video and solo and out_sol is None:\n",
    "                out_sol = cv2.VideoWriter(os.path.join(output_path, 'solo_' + fname), fourcc, \n",
    "                    25.0, (frame.shape[1], frame.shape[0]))\n",
    "                if not out_sol.isOpened():\n",
    "                    raise Exception(\"Cannot open output file.\")\n",
    "            if generate_video and side_by_side and out_sbs is None:\n",
    "                out_sbs = cv2.VideoWriter(os.path.join(output_path, 'side_by_side_' + fname), fourcc, \n",
    "                    25.0, (frame.shape[1] * 2, frame.shape[0]))\n",
    "                if not out_sbs.isOpened():\n",
    "                    raise Exception(\"Cannot open output file.\")\n",
    "            _, _, vis1 = coco_demo.run_on_opencv_image(frame)    \n",
    "            if solo:\n",
    "                if generate_gif:\n",
    "                    gif_sol.append(vis1)\n",
    "                if generate_video:\n",
    "                    out_sol.write(vis1)\n",
    "            if side_by_side:\n",
    "                _, _, vis2 = coco_demo_2.run_on_opencv_image(frame)  \n",
    "                vis_sbs = np.concatenate([vis2, vis1], axis=1)\n",
    "                if generate_gif:\n",
    "                    gif_sbs.append(vis_sbs)\n",
    "                if generate_video:\n",
    "                    out_sbs.write(vis_sbs)\n",
    "        cap.release()\n",
    "        if generate_video and solo:\n",
    "            out_sol.release()\n",
    "            out_sol = None\n",
    "        if generate_video and side_by_side:\n",
    "            out_sbs.release()\n",
    "            out_sbs = None\n",
    "        if generate_gif and solo:\n",
    "            gif_sol = [Image.fromarray(item[:, :, ::-1]) for item in gif_sol]\n",
    "            imageio.mimsave(\n",
    "                os.path.join(output_path, 'solo_' + fname[:-3] + 'gif'), \n",
    "                gif_sol, \n",
    "                'GIF-FI',\n",
    "                fps=25,\n",
    "                quantizer='nq', # The options are 'nq' and 'wu'\n",
    "                loop=0,\n",
    "            )\n",
    "        if generate_gif and side_by_side:\n",
    "            gif_sbs = [Image.fromarray(item[:, :, ::-1]) for item in gif_sbs]\n",
    "            imageio.mimsave(\n",
    "                os.path.join(output_path, 'side_by_side_' + fname[:-3] + 'gif'), \n",
    "                gif_sbs, \n",
    "                'GIF-FI',\n",
    "                fps=25,\n",
    "                quantizer='nq', # The options are 'nq' and 'wu'\n",
    "                loop=0,\n",
    "            )\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        print(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
